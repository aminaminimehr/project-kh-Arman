{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import talib as ta\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Dropout\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('BTC-USD.xlsx' , index_col = 'Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop( ['<TICKER>' ,  '<OPENINT>' , '<OPENINT>.1'  ] , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "## Finding all 0 values which are the sign of closed days and turning them to numpy nan \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [0,1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "pyplot.figure(figsize = (20,10))\n",
    "for group in groups:\n",
    "    pyplot.subplot(len(groups), 1, i)\n",
    "    pyplot.plot(values[:, group])\n",
    "    pyplot.title(df.columns[group], y=0.5, loc='right')\n",
    "    i += 1\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolating the closed days of the stock by linear style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Open'].interpolate(method = 'linear' , inplace = True)\n",
    "df['High'].interpolate(method = 'linear' , inplace = True)\n",
    "df['Low'].interpolate(method = 'linear' , inplace = True)\n",
    "df['Volume'].interpolate(method = 'linear' , inplace = True)\n",
    "df['Close'].interpolate(method = 'linear' , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df['Open']\n",
    "b = df['High']\n",
    "c = df['Low']\n",
    "d = df['Volume']\n",
    "e = df['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame({'Date':df.index, 'Open':a ,'High':b ,'Low':c , 'Close':e ,'Volume': d })\n",
    "df_new.set_index(['Date'] , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_1 = df_new.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "pyplot.figure(figsize = (20,10))\n",
    "for group in groups:\n",
    "    pyplot.subplot(len(groups), 1, i)\n",
    "    pyplot.plot(values_1[:, group])\n",
    "    pyplot.title(df_new.columns[group], y=0.5, loc='right')\n",
    "    i += 1\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the continuing code compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Indicators on the stock (Feature creation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADX - Average Directional Movement Index\n",
    "adx = ta.ADX(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
    "\n",
    "# ADXR - Average Directional Movement Index Rating\n",
    "adxr = ta.ADXR(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
    "\n",
    "# APO - Absolute Price Oscillator\n",
    "apo = ta.APO(df['Close'], fastperiod=12, slowperiod=26, matype=0)\n",
    "\n",
    "# AROON - Aroon\n",
    "aroondown, aroonup = ta.AROON(df['High'], df['Low'], timeperiod=14)\n",
    "\n",
    "# AROONOSC - Aroon Oscillator\n",
    "AROONOSC = ta.AROONOSC(df['High'], df['Low'], timeperiod=14)\n",
    "\n",
    "# BOP - Balance Of Power\n",
    "bop = ta.BOP(df['Open'],df['High'], df['Low'],df['Close'])\n",
    "\n",
    "# CCI - Commodity Channel Index\n",
    "cci = ta.CCI(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
    "\n",
    "# CMO - Chande Momentum Oscillator\n",
    "cmo = ta.CMO(df['Close'], timeperiod=14)\n",
    "\n",
    "# DX - Directional Movement Index\n",
    "dx = ta.DX(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
    "\n",
    "# MACD - Moving Average Convergence/Divergence\n",
    "macd, macdsignal, macdhist = ta.MACD(df['Close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "\n",
    "# MFI - Money Flow Index\n",
    "mfi = ta.MFI(df['High'],df['Low'], df['Close'], df['Volume'], timeperiod=14)\n",
    "\n",
    "# MINUS_DI - Minus Directional Indicator\n",
    "minus_di = ta.MINUS_DI(df['High'],df['Low'], df['Close'], timeperiod=14)\n",
    "\n",
    "# MINUS_DM - Minus Directional Movement\n",
    "minus_dm = ta.MINUS_DM(df['High'], df['Low'], timeperiod=14)\n",
    "\n",
    "# MOM - Momentum\n",
    "momentum = ta.MOM(df['Close'], timeperiod=10)\n",
    "\n",
    "# PLUS_DI - Plus Directional Indicator\n",
    "plus_di = ta.PLUS_DI(df['High'], df['Low'], df['Close'], timeperiod=14)\n",
    "\n",
    "# PLUS_DM - Plus Directional Movement\n",
    "plus_dm = ta.PLUS_DM(df['High'], df['Low'], timeperiod=14)\n",
    "\n",
    "# PPO - Percentage Price Oscillator\n",
    "ppo = ta.PPO(df['Close'], fastperiod=12, slowperiod=26, matype=0)\n",
    "\n",
    "# ROC - Rate of change : ((price/prevPrice)-1)*100\n",
    "roc = ta.ROC(df['Close'], timeperiod=10)\n",
    "\n",
    "# ROCP - Rate of change Percentage: (price-prevPrice)/prevPrice\n",
    "rocp = ta.ROCP(df['Close'], timeperiod=10)\n",
    "\n",
    "# ROCR - Rate of change ratio: (price/prevPrice)\n",
    "rocr = ta.ROCR(df['Close'], timeperiod=10)\n",
    "\n",
    "# ROCR100 - Rate of change ratio 100 scale: (price/prevPrice)*100\n",
    "rocr100 = ta.ROCR100(df['Close'], timeperiod=10)\n",
    "\n",
    "# RSI - Relative Strength Index\n",
    "rsi = ta.RSI(df['Close'], timeperiod=14)\n",
    "\n",
    "#STOCH - Stochastic\n",
    "slowk, slowd = ta.STOCH(df['High'], df['Low'], df['Close'], fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)\n",
    "\n",
    "# STOCHF - Stochastic Fast\n",
    "fastk, fastd = ta.STOCHF(df['High'], df['Low'], df['Close'], fastk_period=5, fastd_period=3, fastd_matype=0)\n",
    "\n",
    "# STOCHRSI - Stochastic Relative Strength Index\n",
    "fastkrsi, fastdrsi = ta.STOCHRSI(df['Close'], timeperiod=14, fastk_period=5, fastd_period=3, fastd_matype=0)\n",
    "\n",
    "# TRIX - 1-day Rate-Of-Change (ROC) of a Triple Smooth EMA\n",
    "trix = ta.TRIX(df['Close'], timeperiod=30)\n",
    "\n",
    "# ULTOSC - Ultimate Oscillator\n",
    "ultosc = ta.ULTOSC(df['High'], df['Low'], df['Close'], timeperiod1=7, timeperiod2=14, timeperiod3=28)\n",
    "\n",
    "# WILLR - Williams' %R\n",
    "willr = ta.WILLR(df['High'], df['Low'],  df['Close'], timeperiod=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indicator DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator = pd.DataFrame({ 'ADX':adx , 'ADXR':adxr , 'APO' :apo , 'AROON_DOWN': aroondown ,'AROON_UP':aroonup , 'AROONOSC' :AROONOSC,\n",
    "                          'BOP':bop , 'CCI':cci ,'CMO':cmo ,'DX': dx , 'MACD': macd ,'MFI':mfi , 'MINUS_DI': minus_di , 'MINUS_DM':minus_dm, \n",
    "                          'MOM':momentum ,'PLUS_DI':plus_di,'PLUS_DM': plus_dm , 'PPO':ppo , 'ROC':roc , 'ROCP':rocp , 'ROCR':rocr ,\n",
    "                         'ROCR100' : rocr100 , 'RSI':rsi ,'STOCK_K':slowk , 'STOCK_D':slowd ,'STOCKF_K':fastk , 'STOCKF_D':fastd,\n",
    "                          'STOCHRSI_k':fastkrsi ,'STOCHRSI_D':fastdrsi,  'TRIX':trix , 'ULTOSC':ultosc , 'WILLR':willr })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator = indicator.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating lag of close price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_price = df['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_price_lag1 = close_price.shift()\n",
    "close_price_lag2 = close_price.shift(2)\n",
    "close_price_lag3 = close_price.shift(3)\n",
    "close_price_lag4 = close_price.shift(4)\n",
    "close_price_lag5 = close_price.shift(5)\n",
    "close_price_lag6 = close_price.shift(6)\n",
    "close_price_lag7 = close_price.shift(7)\n",
    "close_price_lag8 = close_price.shift(8)\n",
    "close_price_lag9 = close_price.shift(9)\n",
    "close_price_lag10 = close_price.shift(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_price_including_lags = pd.DataFrame({'Close':close_price ,'Close LAG1':close_price_lag1 ,'Close LAG2':close_price_lag2\n",
    "                                          ,'Close LAG3':close_price_lag3 ,'Close LAG4':close_price_lag4 ,'Close LAG5':close_price_lag5\n",
    "                                          ,'Close LAG6':close_price_lag6 ,'Close LAG7':close_price_lag7 ,'Close LAG8':close_price_lag8\n",
    "                                          ,'Close LAG9':close_price_lag9 ,'Close LAG10':close_price_lag10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_price_including_lags = close_price_including_lags[88:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_price_including_lags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL DATA FRAME INCLUDING TARGET AND FEATURES\n",
    "# (before feature selection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.concat([df[88:] , indicator] , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.drop('Close' , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.concat([close_price_including_lags , final_data] , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.drop(['Date'] , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature correlation analysis (to see which feature selection suits better)\n",
    "## Random forest vs RFE(linear)\n",
    "### if correlation is low : Rnadom forest and if correlation is high : RFE(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix_features = final_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(corr_matrix_features , cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As the clasifier can only get integers we can multiply all values in 100 to not miss any differnces and boundaries and then convert them into integers to be accepted in the random forrest classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_feature_selection = final_data.drop(['Close'] , axis=1 )\n",
    "y_feature_selection = final_data['Close']\n",
    "\n",
    "X_feature_selection = (X_feature_selection*100).astype(int)\n",
    "y_feature_selection = (y_feature_selection*100).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))\n",
    "sel.fit(X_feature_selection, y_feature_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features= X_feature_selection.columns[(sel.get_support())]\n",
    "number_of_selected_features = len(selected_features)\n",
    "print(number_of_selected_features , 'features have beed choosed through RandomForest Clasifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = selected_features.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL DATA FRAME INCLUDING TARGET AND FEATURES\n",
    "# (after feature selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_df = pd.DataFrame({ 'Close' : final_data['Close'] })\n",
    "selected_features_dataframe = final_data[selected_features]\n",
    "final_data = pd.concat([close_df , selected_features_dataframe] , axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                      Train Test split \n",
    "##                           The sequence is divided into 3 small sequences\n",
    "###                                   (Each small sequence has its own training and test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lenght of the whole sequemce\n",
    "\n",
    "seq_len = len(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lenght of each small sequences\n",
    "\n",
    "small_seq_len = seq_len / 3\n",
    "small_seq_len = int(small_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split for the first sequence\n",
    "### normalisation (fitted on train set and transformed to train and test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_first_seq = final_data[ : int(small_seq_len*0.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test calculation\n",
    "normalizer.fit(train_data_first_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_first_seq = normalizer.transform(train_data_first_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_first_seq = final_data[int(small_seq_len*0.9) : int((small_seq_len*0.9) + small_seq_len*0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_first_seq = normalizer.transform(test_data_first_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split for the second sequence\n",
    "### normalisation (fitted on train set and transformed to train and test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_second_seq = final_data[int((small_seq_len*0.9) + (small_seq_len*0.1)) : int((small_seq_len*0.9) + (small_seq_len*0.1) + \n",
    "                                                                                     (small_seq_len*0.9)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer.fit(train_data_second_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_second_seq = normalizer.transform(train_data_second_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_second_seq = final_data[int((small_seq_len*0.9) + (small_seq_len*0.1) + (small_seq_len*0.9)) : int((small_seq_len*0.9) + (small_seq_len*0.1) + \n",
    "                                                                                     (small_seq_len*0.9) + (small_seq_len*0.1)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_second_seq = normalizer.transform(test_data_second_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split for the third sequence \n",
    "### normalisation (fitted on train set and transformed to train and test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_third_seq = final_data[int((small_seq_len*0.9) + (small_seq_len*0.1) +(small_seq_len*0.9) + (small_seq_len*0.1)) :\n",
    "                                 int((small_seq_len*0.9) + (small_seq_len*0.1) +(small_seq_len*0.9) + (small_seq_len*0.1) +\n",
    "                                    (small_seq_len*0.9))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer.fit(train_data_third_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_third_seq = normalizer.transform(train_data_third_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_third_seq = final_data[int((small_seq_len*0.9) + (small_seq_len*0.1) +(small_seq_len*0.9) + (small_seq_len*0.1) + (small_seq_len*0.9)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_third_seq = normalizer.transform(test_data_third_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runing the first sequence of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into feature and target ( for the first sequence )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Into numpy array\n",
    "train_values = train_data_first_seq\n",
    "test_values = test_data_first_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = train_values[:, 1:], train_values[:, 0]\n",
    "test_X, test_y = test_values[:, 1:], test_values[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "train_y = train_y.reshape(630,1)\n",
    "test_y = test_y.reshape(70,1)\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before starting the model \n",
    "## I created a metric to calculate R^2\n",
    "### it is created as followes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_2(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as k\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "opt = Adam(lr = 1e-6 * 10**(110 / 40) , decay = 0.007) #  , clipnorm=1.0 \n",
    "model.add(LSTM(30 , return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(120, return_sequences = True))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(LSTM(30))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = opt , loss='mae' , metrics = ['mse' ] )\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs = 1000, batch_size=64, validation_data=(test_X, test_y), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(18,6))\n",
    "\n",
    "axes[0].plot(history.history['loss'], label='train')\n",
    "axes[0].plot(history.history['val_loss'], label='test')\n",
    "axes[0].legend()\n",
    "axes[0].set_title('MAE loss')\n",
    "\n",
    "axes[1].plot(history.history['mse'], label='train')\n",
    "axes[1].plot(history.history['val_mse'], label='test')\n",
    "axes[1].legend()\n",
    "axes[1].set_title('MSE loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[14 ,7] , )\n",
    "plt.plot(history.history['R_2'], label='train')\n",
    "plt.plot(history.history['val_R_2'], label='test')\n",
    "plt.legend()\n",
    "plt.title('R^2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model ( for the first sequence )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = np.concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = np.concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,9))\n",
    "plt.plot(yhat.flatten() , 'g-', marker = 'x' , markersize = 5  , label = 'Y_hat')\n",
    "plt.plot(test_y , 'b-' , label = 'Target' )\n",
    "plt.legend()\n",
    "plt.title('F I T')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Close Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runing the second sequence of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into feature and target ( for the second sequence )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Into numpy array\n",
    "train_values = train_data_second_seq\n",
    "test_values = test_data_second_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = train_values[:, 1:], train_values[:, 0]\n",
    "test_X, test_y = test_values[:, 1:], test_values[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model ( for the second sequence )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as k\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "opt = Adam(lr = 1e-6 * 10**(110 / 40) , decay = 0.007) #  , clipnorm=1.0 \n",
    "model.add(LSTM(30, input_shape=(train_X.shape[1], train_X.shape[2]) , return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(120, return_sequences = True))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(LSTM(30))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer = opt , loss='mae' , metrics = ['mse' , R_2 ] )\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs = 1000, batch_size=64, validation_data=(test_X, test_y), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(18,6))\n",
    "\n",
    "axes[0].plot(history.history['loss'], label='train')\n",
    "axes[0].plot(history.history['val_loss'], label='test')\n",
    "axes[0].legend()\n",
    "axes[0].set_title('MAE loss')\n",
    "\n",
    "axes[1].plot(history.history['mse'], label='train')\n",
    "axes[1].plot(history.history['val_mse'], label='test')\n",
    "axes[1].legend()\n",
    "axes[1].set_title('MSE loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[14 ,7] , )\n",
    "plt.plot(history.history['R_2'], label='train')\n",
    "plt.plot(history.history['val_R_2'], label='test')\n",
    "plt.legend()\n",
    "plt.title('R^2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model ( for the second sequence )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = np.concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = np.concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,9))\n",
    "plt.plot(yhat.flatten() , 'g-', marker = 'x' , markersize = 5  , label = 'Y_hat')\n",
    "plt.plot(test_y , 'b-' , label = 'Target' )\n",
    "plt.legend()\n",
    "plt.title('F I T')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Close Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runing the third sequence of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into feature and target ( for the third sequence )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Into numpy array\n",
    "train_values = train_data_third_seq\n",
    "test_values = test_data_third_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = train_values[:, 1:], train_values[:, 0]\n",
    "test_X, test_y = test_values[:, 1:], test_values[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model ( for the third sequence )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as k\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "opt = Adam(lr = 1e-6 * 10**(110 / 40) , decay = 0.007) #  , clipnorm=1.0 \n",
    "model.add(LSTM(30, input_shape=(train_X.shape[1], train_X.shape[2]) , return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(120, return_sequences = True))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(LSTM(30))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer = opt , loss='mae' , metrics = ['mse' , R_2 ] )\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs = 1000, batch_size=64, validation_data=(test_X, test_y), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(18,6))\n",
    "\n",
    "axes[0].plot(history.history['loss'], label='train')\n",
    "axes[0].plot(history.history['val_loss'], label='test')\n",
    "axes[0].legend()\n",
    "axes[0].set_title('MAE loss')\n",
    "\n",
    "axes[1].plot(history.history['mse'], label='train')\n",
    "axes[1].plot(history.history['val_mse'], label='test')\n",
    "axes[1].legend()\n",
    "axes[1].set_title('MSE loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[14 ,7] , )\n",
    "plt.plot(history.history['R_2'], label='train')\n",
    "plt.plot(history.history['val_R_2'], label='test')\n",
    "plt.legend()\n",
    "plt.title('R^2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model ( for the third sequence )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = np.concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = np.concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,9))\n",
    "plt.plot(yhat.flatten() , 'g-', marker = 'x' , markersize = 5  , label = 'Y_hat')\n",
    "plt.plot(test_y , 'b-' , label = 'Target' )\n",
    "plt.legend()\n",
    "plt.title('F I T')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Close Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the whole 10 year in one model and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into feature and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lenght of the whole sequemce\n",
    "seq_len = len(final_data)\n",
    "train_split = int(0.9*seq_len)\n",
    "train_data_whole_seq = final_data[:train_split]\n",
    "normalizer.fit(train_data_whole_seq)\n",
    "train_data_whole_seq = normalizer.transform(train_data_whole_seq)\n",
    "test_data_whole_seq = final_data[train_split:]\n",
    "test_data_whole_seq = normalizer.transform(test_data_whole_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Into numpy array\n",
    "train_values = train_data_whole_seq\n",
    "test_values = test_data_whole_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = train_values[:, 1:], train_values[:, 0]\n",
    "test_X, test_y = test_values[:, 1:], test_values[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model for the whole sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as k\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "opt = Adam(lr = 1e-6 * 10**(110 / 40) , decay = 0.007) #  , clipnorm=1.0 \n",
    "model.add(LSTM(30, input_shape=(train_X.shape[1], train_X.shape[2]) , return_sequences = True))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(LSTM(110, return_sequences = True))\n",
    "model.add(Dropout(0.05))\n",
    "\n",
    "model.add(LSTM(20))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer = opt , loss='mae' , metrics = ['mse' , R_2 ] )\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs = 1000, batch_size=64, validation_data=(test_X, test_y), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(18,6))\n",
    "\n",
    "axes[0].plot(history.history['loss'], label='train')\n",
    "axes[0].plot(history.history['val_loss'], label='test')\n",
    "axes[0].legend()\n",
    "axes[0].set_title('MAE loss')\n",
    "\n",
    "axes[1].plot(history.history['mse'], label='train')\n",
    "axes[1].plot(history.history['val_mse'], label='test')\n",
    "axes[1].legend()\n",
    "axes[1].set_title('MSE loss')\n",
    "#plt.savefig('gru train loggg' , dpi = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[14 ,7] , )\n",
    "plt.plot(history.history['R_2'], label='train')\n",
    "plt.plot(history.history['val_R_2'], label='test')\n",
    "plt.legend()\n",
    "plt.title('R^2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model ( for the whole sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = np.concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = np.concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,9))\n",
    "plt.plot(yhat.flatten()+0.3 , 'g-', marker = 'x' , markersize = 5  , label = 'Y_hat')\n",
    "plt.plot(test_y  , 'b-' , label = 'Target' )\n",
    "plt.legend()\n",
    "plt.title('F I T')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Close Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lstm = yhat.flatten() + 0.3\n",
    "#gru = yhat.flatten() + 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = pd.DataFrame({'LSTM prediction':lstm , 'GRU prediction':gru , 'Date': df.index[-211:]} )\n",
    "zz = zz.set_index ('Date')\n",
    "zz['Target value'] = test_y\n",
    "zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib import style\n",
    "style.use('seaborn')\n",
    "plt.figure(figsize=(18,9))\n",
    "plt.plot(zz['Target value'], 'b-'  , label = 'Target')\n",
    "plt.plot(zz['LSTM prediction'] , 'g-*'  , markersize = 8 , label = 'LSTM prediction' )\n",
    "plt.plot(zz['GRU prediction'] , 'r-*'  , markersize = 8 , label = 'GRU prediction' )\n",
    "plt.legend()\n",
    "plt.title('F I T')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Close Price scaled')\n",
    "#plt.savefig('fig plot gru lstm bitcoin' , dpi = 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zz.to_csv('fit plot lstm gru bitcoin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
